{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_jO-FK2h_9bB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download the MNIST dataset\n",
        "torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "# Step 2: Load the raw MNIST dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "zpKE0cMQCiLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3cd622-8946-43db-f37d-2afde34036ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 537kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.78MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.90MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the datasets\n",
        "def show_images(images, labels, label_header=\"True\"):\n",
        "    figure = plt.figure(figsize=(10, 10))\n",
        "    rows, cols = 1, 4\n",
        "    for i in range(1, rows*cols+1):\n",
        "        figure.add_subplot(rows, cols, i)\n",
        "        plt.axis(False)\n",
        "        plt.title(f\"{label_header}: {labels[i-1].item()}\")\n",
        "        plt.imshow(images[i-1].permute(1, 2, 0), cmap='gray')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images and show\n",
        "images, labels = next(iter(trainloader))\n",
        "show_images(images, labels, label_header=\"Raw\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "WIo50iBS_9x9",
        "outputId": "0394f31a-6779-4101-a3ee-9d6229a697c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mWPjnMrWPm8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocessing Step: Normalization and Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomRotation(10),  # Randomly rotate the image by 10 degrees\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1)),  # Random translation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize the same way for test set\n",
        "])"
      ],
      "metadata": {
        "id": "vRBLQe78AYkf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zcj4_O0YCgja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load the MNIST dataset with preprocessing applied\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Visualize Some Preprocessed Images\n",
        "preprocessed_images, preprocessed_labels = next(iter(trainloader))\n",
        "show_images(preprocessed_images, preprocessed_labels, label_header=\"Preprocessed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "EvP-1L6s8pR4",
        "outputId": "51cf8b83-e51f-48ac-a264-ad999ac49459"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mlp model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "UrKMtie6a3u_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        # Flatten input (28x28) to 784\n",
        "        self.flatten = nn.Flatten()\n",
        "        # Define MLP layers\n",
        "        self.fc1 = nn.Linear(28*28, 256)  # First fully connected layer\n",
        "        self.fc2 = nn.Linear(256, 128)    # Second fully connected layer\n",
        "        self.fc3 = nn.Linear(128, 64)     # Third fully connected layer\n",
        "        self.fc4 = nn.Linear(64, 10)      # Output layer (10 classes)\n",
        "        self.relu = nn.ReLU()             # ReLU activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)  # No activation in the last layer (we'll use CrossEntropyLoss which combines softmax)\n",
        "        return x\n",
        "\n",
        "# Step 2: Initialize model, loss function, and optimizer\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross entropy loss combines softmax and loss calculation\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam optimizer"
      ],
      "metadata": {
        "id": "PC4jNIEkBOTa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Training function\n",
        "def train(model, trainloader, criterion, optimizer, epochs=20):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in trainloader:\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Print statistics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.2f}%,\")"
      ],
      "metadata": {
        "id": "Cxy2QhBfbGau"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluation function\n",
        "def evaluate(model, testloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())  # Convert lists to numpy arrays\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "     # Step 5: Compute evaluation metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall: {recall:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}%\")\n"
      ],
      "metadata": {
        "id": "2sITakLIbP_E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the model\n",
        "train(model, trainloader, criterion, optimizer, epochs=20)\n",
        "\n",
        "# Step 7: Evaluate the model on the test set\n",
        "evaluate(model, testloader)\n",
        "\n",
        "# save the model weights\n",
        "model_1 = MLP()  # Create the model instance\n",
        "torch.save(model_1 ,\"mlp_mnist_weights.pth\")\n",
        "print(\"Mlp Model weights saved successfully.\")\n"
      ],
      "metadata": {
        "id": "9BkiM-dZbYdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1199adc0-b76b-4570-e19a-813740324a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.2570, Training Accuracy: 91.98%,\n",
            "Epoch [2/20], Loss: 0.2157, Training Accuracy: 93.15%,\n",
            "Epoch [3/20], Loss: 0.1907, Training Accuracy: 93.89%,\n",
            "Epoch [4/20], Loss: 0.1749, Training Accuracy: 94.37%,\n",
            "Epoch [5/20], Loss: 0.1614, Training Accuracy: 94.88%,\n",
            "Epoch [6/20], Loss: 0.1570, Training Accuracy: 94.94%,\n",
            "Epoch [7/20], Loss: 0.1452, Training Accuracy: 95.41%,\n",
            "Epoch [8/20], Loss: 0.1430, Training Accuracy: 95.53%,\n",
            "Epoch [9/20], Loss: 0.1420, Training Accuracy: 95.50%,\n",
            "Epoch [10/20], Loss: 0.1297, Training Accuracy: 95.95%,\n",
            "Epoch [11/20], Loss: 0.1282, Training Accuracy: 95.88%,\n",
            "Epoch [12/20], Loss: 0.1219, Training Accuracy: 96.16%,\n",
            "Epoch [13/20], Loss: 0.1207, Training Accuracy: 96.16%,\n",
            "Epoch [14/20], Loss: 0.1147, Training Accuracy: 96.30%,\n",
            "Epoch [15/20], Loss: 0.1135, Training Accuracy: 96.46%,\n",
            "Epoch [16/20], Loss: 0.1135, Training Accuracy: 96.45%,\n",
            "Epoch [17/20], Loss: 0.1104, Training Accuracy: 96.53%,\n",
            "Epoch [18/20], Loss: 0.1061, Training Accuracy: 96.66%,\n",
            "Epoch [19/20], Loss: 0.1059, Training Accuracy: 96.68%,\n",
            "Epoch [20/20], Loss: 0.1042, Training Accuracy: 96.61%,\n",
            "Test Accuracy: 98.04%\n",
            "Precision: 98.05%\n",
            "Recall: 98.04%\n",
            "F1 Score: 98.04%\n",
            "Mlp Model weights saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Convolutional layer\n",
        "        # 1 input channel (grayscale), 16 filters, kernel size 3x3, and padding of 1 to maintain size\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        # Pooling layer to reduce spatial dimensions\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Fully connected layer\n",
        "        # Input size is determined by the number of filters (16) and reduced image size (14x14 after pooling)\n",
        "        self.fc1 = nn.Linear(16 * 14 * 14, 10)  # Output is 10 classes (digits 0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the convolutional layer followed by ReLU activation and max pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # Flatten the output of the convolutional layer to pass it into the fully connected layer\n",
        "        x = x.view(-1, 16 * 14 * 14)\n",
        "        # Apply the fully connected layer\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "cnn_model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross entropy for classification\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)  # Adam optimizer\n"
      ],
      "metadata": {
        "id": "irJIYVGWnehr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_cnn(model, trainloader, criterion, optimizer, epochs=20):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in trainloader:\n",
        "            # Zero the gradients from the previous step\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass: compute predictions\n",
        "            outputs = model(images)\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Backward pass: compute gradients\n",
        "            loss.backward()\n",
        "            # Update the model parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate epoch loss and accuracy\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "lXh5l0Ivn2dq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_cnn(model, testloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall: {recall:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}%\")"
      ],
      "metadata": {
        "id": "617Edf7un8dR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN model\n",
        "train_cnn(cnn_model, trainloader, criterion, optimizer, epochs=20)\n",
        "\n",
        "# Evaluate the CNN model on the test set\n",
        "evaluate_cnn(cnn_model, testloader)\n",
        "\n",
        "# save the model weights\n",
        "model_2 = CNN()  # Create the model instance\n",
        "torch.save(model_2 ,\"cnn_mnist_weights.pth\")\n",
        "print(\"Cnn Model weights saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zRVNypirA6",
        "outputId": "119f2502-c164-45e3-afdf-f1a0378f3d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.5278, Training Accuracy: 84.32%\n",
            "Epoch [2/20], Loss: 0.2757, Training Accuracy: 91.60%\n",
            "Epoch [3/20], Loss: 0.2459, Training Accuracy: 92.52%\n",
            "Epoch [4/20], Loss: 0.2295, Training Accuracy: 92.91%\n",
            "Epoch [5/20], Loss: 0.2183, Training Accuracy: 93.30%\n",
            "Epoch [6/20], Loss: 0.2096, Training Accuracy: 93.71%\n",
            "Epoch [7/20], Loss: 0.2002, Training Accuracy: 94.01%\n",
            "Epoch [8/20], Loss: 0.1930, Training Accuracy: 94.20%\n",
            "Epoch [9/20], Loss: 0.1882, Training Accuracy: 94.36%\n",
            "Epoch [10/20], Loss: 0.1815, Training Accuracy: 94.48%\n",
            "Epoch [11/20], Loss: 0.1784, Training Accuracy: 94.58%\n",
            "Epoch [12/20], Loss: 0.1729, Training Accuracy: 94.77%\n",
            "Epoch [13/20], Loss: 0.1694, Training Accuracy: 94.91%\n",
            "Epoch [14/20], Loss: 0.1637, Training Accuracy: 95.01%\n",
            "Epoch [15/20], Loss: 0.1611, Training Accuracy: 95.12%\n",
            "Epoch [16/20], Loss: 0.1570, Training Accuracy: 95.22%\n",
            "Epoch [17/20], Loss: 0.1554, Training Accuracy: 95.34%\n",
            "Epoch [18/20], Loss: 0.1544, Training Accuracy: 95.44%\n",
            "Epoch [19/20], Loss: 0.1536, Training Accuracy: 95.42%\n",
            "Epoch [20/20], Loss: 0.1475, Training Accuracy: 95.50%\n",
            "Test Accuracy: 98.07%\n",
            "Precision: 98.08%\n",
            "Recall: 98.07%\n",
            "F1 Score: 98.07%\n",
            "Cnn Model weights saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "1iRuhgzsm5-e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # Convolutional and pooling layers\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)  # Input: 28x28, Output: 28x28\n",
        "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Input: 28x28, Output: 14x14\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Input: 14x14, Output: 10x10\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Input: 10x10, Output: 5x5\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Flattened to 16x5x5, Output: 120\n",
        "        self.fc2 = nn.Linear(120, 84)  # Output: 84\n",
        "        self.fc3 = nn.Linear(84, 10)  # Output: 10 (for 10 digits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(-1, 16 * 5 * 5)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # No activation on the final layer\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "dG0fqaxjnB0o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LeNet-5 model\n",
        "model_3 = LeNet5()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross entropy loss for multi-class classification\n",
        "optimizer = optim.Adam(model_3.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Training function\n",
        "def train_lenet5(model, trainloader, criterion, optimizer, epochs=20):\n",
        "    model.train()    # Set the model to training mode\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in trainloader:\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()  # Backward pass and optimization\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()  # Statistics\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "       # Print statistics\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Training Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "KEeO84lPnLyq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_lenet5(model, testloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())  # Convert lists to numpy arrays\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
        "    precision = precision_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "    recall = recall_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\") * 100\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall: {recall:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ohO1mFbnnTyv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LeNet-5 model\n",
        "train_lenet5(model_3, trainloader, criterion, optimizer, epochs=20)\n",
        "\n",
        "# Evaluate the LeNet-5 model on the test set\n",
        "evaluate_lenet5(model_3, testloader)\n",
        "\n",
        "torch.save(model_3.state_dict(), \"lenet5_weights.pth\")\n",
        "print(\"Lenet5 Model weights saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEu1Ro1LYp9U",
        "outputId": "1ac083df-e612-404b-b3eb-e1a557dc5779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.0332, Training Accuracy: 98.94%\n",
            "Epoch [2/20], Loss: 0.0320, Training Accuracy: 98.97%\n",
            "Epoch [3/20], Loss: 0.0325, Training Accuracy: 98.95%\n",
            "Epoch [4/20], Loss: 0.0326, Training Accuracy: 98.93%\n",
            "Epoch [5/20], Loss: 0.0300, Training Accuracy: 99.10%\n",
            "Epoch [6/20], Loss: 0.0310, Training Accuracy: 99.02%\n",
            "Epoch [7/20], Loss: 0.0308, Training Accuracy: 99.00%\n",
            "Epoch [8/20], Loss: 0.0309, Training Accuracy: 99.04%\n",
            "Epoch [9/20], Loss: 0.0285, Training Accuracy: 99.12%\n",
            "Epoch [10/20], Loss: 0.0286, Training Accuracy: 99.11%\n",
            "Epoch [11/20], Loss: 0.0282, Training Accuracy: 99.11%\n",
            "Epoch [12/20], Loss: 0.0285, Training Accuracy: 99.10%\n",
            "Epoch [13/20], Loss: 0.0268, Training Accuracy: 99.16%\n",
            "Epoch [14/20], Loss: 0.0265, Training Accuracy: 99.13%\n",
            "Epoch [15/20], Loss: 0.0269, Training Accuracy: 99.15%\n",
            "Epoch [16/20], Loss: 0.0266, Training Accuracy: 99.15%\n",
            "Epoch [17/20], Loss: 0.0257, Training Accuracy: 99.16%\n",
            "Epoch [18/20], Loss: 0.0253, Training Accuracy: 99.21%\n",
            "Epoch [19/20], Loss: 0.0261, Training Accuracy: 99.12%\n",
            "Epoch [20/20], Loss: 0.0227, Training Accuracy: 99.28%\n",
            "Test Accuracy: 99.30%\n",
            "Precision: 99.30%\n",
            "Recall: 99.30%\n",
            "F1 Score: 99.30%\n",
            "Lenet5 Model weights saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_sample_image(model, testloader):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Get a single batch of data from the testloader\n",
        "    images, labels = next(iter(testloader))\n",
        "\n",
        "    # Ensure images and labels are on the CPU\n",
        "    images, labels = images.cpu(), labels.cpu()\n",
        "\n",
        "    # Get the model's prediction for the first image in the batch\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Select the first image in the batch\n",
        "    image = images[0]  # The first image in the batch\n",
        "    true_label = labels[0].item()  # Get the true label (first element in the batch)\n",
        "    pred_label = predicted[0].item()  # Get the predicted label (first element in the batch)\n",
        "\n",
        "    # Convert the image from PyTorch tensor to NumPy array for visualization\n",
        "    image = image.numpy()  # Convert to numpy array (channel, height, width)\n",
        "\n",
        "    # Handle grayscale image (LeNet input is typically grayscale, so we use the first channel)\n",
        "    image = image[0]  # We only need the first channel (grayscale image)\n",
        "\n",
        "    # Plot the image and display the true and predicted labels\n",
        "    plt.imshow(image, cmap='gray')  # Display in grayscale\n",
        "    plt.title(f\"True Label: {true_label}, Predicted: {pred_label}\")\n",
        "    plt.axis('off')  # Hide axis\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a sample image\n",
        "visualize_sample_image(model_3, testloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "JZ4GB5UWotv4",
        "outputId": "88466296-6128-48fd-948b-f4ba3896c029"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}